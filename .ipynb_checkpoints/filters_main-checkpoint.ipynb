{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-11 19:49:50.193144: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-11 19:49:50.193162: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "#IMPORTING LIBRARIES\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Conv2D,Activation,Dense,Input, MaxPooling2D , ZeroPadding2D,Flatten\n",
    "from keras.models import Model, load_model,Sequential\n",
    "from math import hypot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: /home/aftab/minor_project/Snapchat-Filter-using-Transfer-Learning/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30724/1218231850.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/aftab/minor_project/Snapchat-Filter-using-Transfer-Learning'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    116\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cannot parse file {path_to_pbtxt}: {str(e)}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     raise IOError(\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;34mf\"SavedModel file does not exist at: {export_dir}{os.path.sep}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;34mf\"{{{constants.SAVED_MODEL_FILENAME_PBTXT}|\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: /home/aftab/minor_project/Snapchat-Filter-using-Transfer-Learning/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "new_model=load_model('/home/aftab/minor_project/Snapchat-Filter-using-Transfer-Learning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glasses():\n",
    "\n",
    "    while True:\n",
    "        check,frame=vid.read()\n",
    "        img=cv2.resize(frame,(200,200))\n",
    "        img1 =img/255\n",
    "        grey=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        faces=face_cascade.detectMultiScale(grey,scaleFactor=1.05,minNeighbors=5)\n",
    "        if len(faces)>0:\n",
    "            #img = flower_crown(img1,img)\n",
    "            #img = glasses(img1,img)\n",
    "    \n",
    "            img1 = np.reshape(img1,[1,200,200,3])\n",
    "\n",
    "            h=new_model.predict(img1)\n",
    "            h=h.round()\n",
    "            h=h.astype(int)\n",
    "            x=np.where( h[:,0:194]>=200,199, h[:,0:194])\n",
    "            y=np.where( h[:,194:]>=200,199, h[:,194:])\n",
    "            img = np.reshape(img,[200,200,3])\n",
    "            #for i in range(0,194):\n",
    "             #   img[y[:,i],x[:,i],:]=255\n",
    "            img = cv2.resize(img,(500,500))\n",
    "\n",
    "            glass = cv2.imread('glass3.PNG')\n",
    "            eye_left= np.array((x[:,145],y[:,145]))*2.5\n",
    "            eye_right= np.array((x[:,125],y[:,125]))*2.5\n",
    "            eye_width= int(hypot(int(eye_left[0]) - int(eye_right[0]) , int(eye_left[1]) - int(eye_right[1]))*1.7)\n",
    "            eye_height = int(eye_width*(glass.shape[0]/glass.shape[1]))\n",
    "            glass= cv2.resize(glass,(eye_width,eye_height))\n",
    "\n",
    "            #glass1 =np.where(glass>200,0,glass)\n",
    "            eye_center = (eye_right + eye_left)/2\n",
    "            top_left = (int(eye_center[0]-eye_width/2),int(eye_center[1]-eye_height/2))\n",
    "            bottom_right = eye_center[0]+eye_width/2,eye_center[1]+eye_height/2\n",
    "\n",
    "            frame= img[ top_left[1]:top_left[1]+eye_height,top_left[0]: top_left[0]+ eye_width]\n",
    "            glass_gray = cv2.cvtColor(glass,cv2.COLOR_BGR2GRAY)\n",
    "            a,mask=cv2.threshold(glass_gray,10,255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "            extra_area= cv2.bitwise_and(frame,frame,mask=mask)\n",
    "            final_glass = cv2.add(extra_area,glass)\n",
    "\n",
    "            img[ top_left[1]:top_left[1]+eye_height,top_left[0]: top_left[0]+ eye_width]= final_glass\n",
    "\n",
    "    \n",
    "    \n",
    "        img =cv2.resize(img,(500,500))\n",
    "        cv2.imshow(\"a\",img)\n",
    "        key=cv2.waitKey(1)\n",
    "        if (key==ord('q')):\n",
    "            break;\n",
    "    \n",
    "  #  return img\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flower_crown():\n",
    "\n",
    "    while True:\n",
    "        check,frame=vid.read()\n",
    "        img=cv2.resize(frame,(200,200))\n",
    "        img1 =img/255\n",
    "        grey=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        faces=face_cascade.detectMultiScale(grey,scaleFactor=1.05,minNeighbors=5)\n",
    "        if len(faces)>0:\n",
    "    \n",
    "            img1 = np.reshape(img1,[1,200,200,3])\n",
    "\n",
    "            h=new_model.predict(img1)\n",
    "            h=h.round()\n",
    "            h=h.astype(int)\n",
    "            x=np.where( h[:,0:194]>=200,199, h[:,0:194])\n",
    "            y=np.where( h[:,194:]>=200,199, h[:,194:])\n",
    "            img = np.reshape(img,[200,200,3])\n",
    "            #for i in range(0,194):\n",
    "             #   img[y[:,i],x[:,i],:]=255\n",
    "            img = cv2.resize(img,(500,500))\n",
    "\n",
    "            glass = cv2.imread('original.jpg')\n",
    "            eye_left= np.array((x[:,145],y[:,145]))*2.5\n",
    "            eye_right= np.array((x[:,125],y[:,125]))*2.5\n",
    "            eye_width= int(hypot(int(eye_left[0]) - int(eye_right[0]) , int(eye_left[1]) - int(eye_right[1]))*2.3)\n",
    "            eye_height = int(eye_width*(glass.shape[0]/glass.shape[1]))\n",
    "            glass= cv2.resize(glass,(eye_width,eye_height))\n",
    "\n",
    "            #glass1 =np.where(glass>200,0,glass)\n",
    "            eye_center = (eye_right + eye_left)/2\n",
    "            top_left = np.array((int(eye_center[0]-eye_width/2),int(eye_center[1]-eye_height/2)-125))\n",
    "            top_left = np.where(top_left<=0,0,top_left)\n",
    "            bottom_right = eye_center[0]+eye_width/2,eye_center[1]+eye_height/2\n",
    "\n",
    "            frame= img[ top_left[1]:top_left[1]+eye_height,top_left[0]: top_left[0]+ eye_width]\n",
    "            glass_gray = cv2.cvtColor(glass,cv2.COLOR_BGR2GRAY)\n",
    "            a,mask=cv2.threshold(glass_gray,10,255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "            extra_area= cv2.bitwise_and(frame,frame,mask=mask)\n",
    "            final_glass = cv2.add(extra_area,glass)\n",
    "\n",
    "            img[ top_left[1]:top_left[1]+eye_height,top_left[0]: top_left[0]+ eye_width]= final_glass\n",
    "\n",
    "    \n",
    "    \n",
    "        img =cv2.resize(img,(500,500))\n",
    "        cv2.imshow(\"a\",img)\n",
    "        key=cv2.waitKey(1)\n",
    "        if (key==ord('q')):\n",
    "            break;\n",
    "    \n",
    "  #  return img\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-aadd3a516524>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mflower_crown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-ed59c8449186>\u001b[0m in \u001b[0;36mflower_crown\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0meye_right\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m125\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m125\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0meye_width\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhypot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meye_left\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meye_right\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meye_left\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meye_right\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0meye_height\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meye_width\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mglass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[0mglass\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglass\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meye_width\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meye_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "face_cascade = cv2.CascadeClassifier('C:\\\\Users\\\\YASH\\\\Anaconda3\\\\Lib\\\\site-packages\\\\cv2\\\\data\\\\haarcascade_frontalface_default.xml')\n",
    "vid=cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    check,frame=vid.read()\n",
    "    '''\n",
    "    img=cv2.resize(frame,(200,200))\n",
    "    img1 =img/255\n",
    "    grey=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_cascade.detectMultiScale(grey,scaleFactor=1.05,minNeighbors=5)\n",
    "    if len(faces)>0:\n",
    "        #img = flower_crown(img1,img)\n",
    "        img = glasses(img1,img)\n",
    "    ''' \n",
    "#     print(np.shape(frame))\n",
    "    img =cv2.resize(frame,(500,500))\n",
    "    cv2.imshow(\"a\",img)\n",
    "    \n",
    "    \n",
    "    key=cv2.waitKey(1)\n",
    "    if (key==ord('a')):\n",
    "        glasses();\n",
    "        \n",
    "    if (key==ord('b')):\n",
    "        flower_crown();\n",
    "        \n",
    "    if (key==ord('c')):\n",
    "        break;\n",
    "        \n",
    "        \n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "glass = cv2.imread('C:\\\\Users\\\\YASH\\\\Desktop\\\\original.jpg')\n",
    "glass= cv2.resize(glass,(100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "       247, 248, 249, 250, 251, 252, 253, 254, 255], dtype=uint8)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(glass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('gh',glass)\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef flower_crown():\\n    img1 = np.reshape(img1,[1,200,200,3])\\n    h=new_model.predict(img1)\\n    h=h.round()\\n    h=h.astype(int)\\n    x=np.where( h[:,0:194]>=200,199, h[:,0:194])\\n    y=np.where( h[:,194:]>=200,199, h[:,194:])\\n    img = np.reshape(img,[200,200,3])\\n    img = cv2.resize(img,(500,500))\\n    #for i in range(0,194):\\n    #    img[y[:,i],x[:,i],:]=255\\n    \\n    glass = cv2.imread('C:\\\\Users\\\\YASH\\\\Desktop\\\\original.jpg')\\n    eye_left= np.array((x[:,145],y[:,145]))*2.5\\n    eye_right= np.array((x[:,125],y[:,125]))*2.5\\n    eye_width= (int(hypot(int(eye_left[0]) - int(eye_right[0]) , int(eye_left[1]) - int(eye_right[1]))*2.3))\\n    eye_height = int(eye_width*(glass.shape[0]/glass.shape[1]))\\n    glass= cv2.resize(glass,(eye_width,eye_height))\\n    \\n    #glass1 =np.where(glass>200,0,glass)\\n    eye_center = (eye_right + eye_left)/2\\n    top_left = (int(eye_center[0]-eye_width/2),int(eye_center[1]-eye_height/2)-125)\\n    bottom_right = eye_center[0]+eye_width/2,eye_center[1]+eye_height/2\\n\\n    frame= img[ top_left[1]:top_left[1]+eye_height,top_left[0]: top_left[0]+ eye_width]\\n    glass_gray = cv2.cvtColor(glass,cv2.COLOR_BGR2GRAY)\\n    a,mask=cv2.threshold(glass_gray,10,255,cv2.THRESH_BINARY_INV)\\n\\n    extra_area= cv2.bitwise_and(frame,frame,mask=mask)\\n    final_glass = cv2.add(extra_area,glass)\\n\\n    img[ top_left[1]:top_left[1]+eye_height,top_left[0]: top_left[0]+ eye_width]= final_glass\\n    \\n    return img\\n\\n \""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def flower_crown():\n",
    "    img1 = np.reshape(img1,[1,200,200,3])\n",
    "    h=new_model.predict(img1)\n",
    "    h=h.round()\n",
    "    h=h.astype(int)\n",
    "    x=np.where( h[:,0:194]>=200,199, h[:,0:194])\n",
    "    y=np.where( h[:,194:]>=200,199, h[:,194:])\n",
    "    img = np.reshape(img,[200,200,3])\n",
    "    img = cv2.resize(img,(500,500))\n",
    "    #for i in range(0,194):\n",
    "    #    img[y[:,i],x[:,i],:]=255\n",
    "    \n",
    "    glass = cv2.imread('C:\\\\Users\\\\YASH\\\\Desktop\\\\original.jpg')\n",
    "    eye_left= np.array((x[:,145],y[:,145]))*2.5\n",
    "    eye_right= np.array((x[:,125],y[:,125]))*2.5\n",
    "    eye_width= (int(hypot(int(eye_left[0]) - int(eye_right[0]) , int(eye_left[1]) - int(eye_right[1]))*2.3))\n",
    "    eye_height = int(eye_width*(glass.shape[0]/glass.shape[1]))\n",
    "    glass= cv2.resize(glass,(eye_width,eye_height))\n",
    "    \n",
    "    #glass1 =np.where(glass>200,0,glass)\n",
    "    eye_center = (eye_right + eye_left)/2\n",
    "    top_left = (int(eye_center[0]-eye_width/2),int(eye_center[1]-eye_height/2)-125)\n",
    "    bottom_right = eye_center[0]+eye_width/2,eye_center[1]+eye_height/2\n",
    "\n",
    "    frame= img[ top_left[1]:top_left[1]+eye_height,top_left[0]: top_left[0]+ eye_width]\n",
    "    glass_gray = cv2.cvtColor(glass,cv2.COLOR_BGR2GRAY)\n",
    "    a,mask=cv2.threshold(glass_gray,10,255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    extra_area= cv2.bitwise_and(frame,frame,mask=mask)\n",
    "    final_glass = cv2.add(extra_area,glass)\n",
    "\n",
    "    img[ top_left[1]:top_left[1]+eye_height,top_left[0]: top_left[0]+ eye_width]= final_glass\n",
    "    \n",
    "    return img\n",
    "\n",
    " '''   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
